All notes goes here...


libs:
    requests – для работы с HTTP-запросами.
    selenium – если сайт использует JavaScript для загрузки данных.

    BeautifulSoup – для разбора и извлечения данных из HTML/XML.
    xml – быстрая альтернатива BeautifulSoup для обработки HTML/XML.

chat gpt's code example for
    import requests
    from urllib.robotparser import RobotFileParser

    url = "https://example.com/robots.txt"
    parser = RobotFileParser()
    parser.set_url(url)
    parser.read()

    if parser.can_fetch('*', 'https://example.com/page'):
        print("Можно парсить эту страницу")
    else:
        print("Парсить запрещено")


-    збегайте слишком частых запросов, чтобы не перегружать сервер.
-   Используйте механизмы time.sleep() или настройки ограничения скорости.